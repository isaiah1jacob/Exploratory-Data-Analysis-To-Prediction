{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploratory Data Analysis To Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peh1OhE0Gyee"
      },
      "source": [
        "#The Objective of this notebook is to give an idea how is the workflow in any predictive modeling problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzgEPcUSG5wF"
      },
      "source": [
        "###Exploratory Data Analysis(EDA):\n",
        "1. Analysis of the features.\n",
        "\n",
        "2. Finding any relations or trends considering multiple features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMMIcEvtG_Ud"
      },
      "source": [
        "#Feature Engineering and Data Cleaning\n",
        "1. Adding any few features.\n",
        "\n",
        "2. Removing redundant features.\n",
        "\n",
        "3. Converting features into suitable form for modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zggc5-ZHaJM"
      },
      "source": [
        "#Predictive Modeling\n",
        "1. Running Basic Algorithms.\n",
        "\n",
        "2. Cross Validation.\n",
        "\n",
        "3. Ensembling.\n",
        "\n",
        "4. Important Features Extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhpuNgYnHqHM"
      },
      "source": [
        "#Exploratory Data Analysis {EDA}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETssOWdJHsHt"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('fivethirtyeight')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQYDt8zkH62c"
      },
      "source": [
        "data=pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58_MrOVOIC-F"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUpU5vBGWPK4"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4p1ksA1Whut"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l43aaNp2IKd8"
      },
      "source": [
        "data.isnull().sum() #checking for total null values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdFiZXPITcU"
      },
      "source": [
        "###The Age, Cabin and Embarked have null values. I will try to fix them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWmtC6CoIWaE"
      },
      "source": [
        "#How many Survived?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjC6Al3TIcM0"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
        "data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
        "ax[0].set_title('Survived')\n",
        "ax[0].set_ylabel('')\n",
        "sns.countplot('Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('Survived')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbdjAUAInWV"
      },
      "source": [
        "#Types Of Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAcNvoeWIojc"
      },
      "source": [
        "#Categorical Features: \n",
        "They are also known as Nominal Variables.\n",
        "Categorical Features in the dataset: **Sex, Embarked.**\n",
        "\n",
        "#Ordinal Features: \n",
        "If we have a feature like Height with values Tall, Medium, Short, then Height is a ordinal variable.\n",
        "Ordinal Features in the dataset: **PClass**\n",
        "\n",
        "#Continous Feature:\n",
        "A feature is said to be continous if it can take values between any two points or between the minimum or maximum values in the features column.\n",
        "Continous Features in the dataset: **Age**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6jopglVJqAL"
      },
      "source": [
        "#Analysing The Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "easbUtVsJvDC"
      },
      "source": [
        "###Sex-> Categorical Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajDV1E2uJy9R"
      },
      "source": [
        "data.groupby(['Sex','Survived'])['Survived'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxCNe44zJ51j"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
        "data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
        "ax[0].set_title('Survived vs Sex')\n",
        "sns.countplot('Sex',hue='Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('Sex:Survived vs Dead')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxkBtlf4KD0E"
      },
      "source": [
        "###This looks to be a very important feature for modeling. But is it the best?? Lets check other features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvH1X5sGKIZL"
      },
      "source": [
        "#Pclass-> Ordinal Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ3PoOIEKL0D"
      },
      "source": [
        "pd.crosstab(data.Pclass,data.Survived,margins=True).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTRZ9msnKSIb"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
        "data['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])\n",
        "ax[0].set_title('Number Of Passengers By Pclass')\n",
        "ax[0].set_ylabel('Count')\n",
        "sns.countplot('Pclass',hue='Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('Pclass:Survived vs Dead')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aVtGl_AKcZz"
      },
      "source": [
        "###For Pclass 1 %survived is around 63% while for Pclass2 is around 48%. So money and status matters. Such a materialistic world.\n",
        "\n",
        "###Lets Dive in little bit more and check for other interesting observations. Lets check survival rate with Sex and Pclass Together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77lWvywsKj-7"
      },
      "source": [
        "pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsb4YNx7KrWL"
      },
      "source": [
        "sns.factorplot('Pclass','Survived',hue='Sex',data=data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id-UoexRKz0M"
      },
      "source": [
        "###We use ***FactorPlot*** in this case, because they make the seperation of categorical values easy.\n",
        "\n",
        "###Looking at the CrossTab and the FactorPlot, we can easily infer that survival for Women from Pclass1 is about ***95-96%,*** as only 3 out of 94 Women from Pclass1 died"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nACNqFnuLCPr"
      },
      "source": [
        "#Age-> Continous Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYdrS_siLFg8"
      },
      "source": [
        "print('Oldest Passenger was of:',data['Age'].max(),'Years')\n",
        "print('Youngest Passenger was of:',data['Age'].min(),'Years')\n",
        "print('Average Age on the ship:',data['Age'].mean(),'Years')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCI7wsHPLMHj"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
        "sns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[0])\n",
        "ax[0].set_title('Pclass and Age vs Survived')\n",
        "ax[0].set_yticks(range(0,110,10))\n",
        "sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\n",
        "ax[1].set_title('Sex and Age vs Survived')\n",
        "ax[1].set_yticks(range(0,110,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFicO4gvLRci"
      },
      "source": [
        "#Observations\n",
        "\n",
        "1. The number of children increases with Pclass and the survival rate for passenegers below Age 10(i.e children) looks to be good irrespective of the Pclass.\n",
        "\n",
        "2. Survival chances for Passenegers aged 20-50 from Pclass1 is high and is even better for Women.\n",
        "\n",
        "3. For males, the survival chances decreases with an increase in age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuOLHSa3LtKm"
      },
      "source": [
        "data['Initial']=0\n",
        "for i in data:\n",
        "    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6HuFWUuLzkF"
      },
      "source": [
        "Okay so here we are using the Regex: [A-Za-z]+).. So what it does is, it looks for strings which lie between A-Z or a-z and followed by a .(dot). So we successfully extract the Initials from the Name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu-_gB78L0WS"
      },
      "source": [
        "pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r') #Checking the Initials with the Sex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aZKHPBjL_Vy"
      },
      "source": [
        "Okay so there are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I544o7ZMAai"
      },
      "source": [
        "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yJRykIMGW6"
      },
      "source": [
        "data.groupby('Initial')['Age'].mean() #lets check the average age by Initials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_gGV32oMMTi"
      },
      "source": [
        "Filling NaN Ages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRhh0qVqMQMa"
      },
      "source": [
        "## Assigning the NaN Values with the Ceil values of the mean ages\n",
        "data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\n",
        "data.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\n",
        "data.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\n",
        "data.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\n",
        "data.loc[(data.Age.isnull())&(data.Initial=='Other'),'Age']=46"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re8mIpqVMThS"
      },
      "source": [
        "data.Age.isnull().any() #So no null values left finally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O93a9F6MW7q"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
        "data[data['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\n",
        "ax[0].set_title('Survived= 0')\n",
        "x1=list(range(0,85,5))\n",
        "ax[0].set_xticks(x1)\n",
        "data[data['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\n",
        "ax[1].set_title('Survived= 1')\n",
        "x2=list(range(0,85,5))\n",
        "ax[1].set_xticks(x2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ab3Mwr9MdRS"
      },
      "source": [
        "Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePWX7y_rMjv6"
      },
      "source": [
        "1. The Toddlers(age<5) were saved in large numbers(The Women and Child First Policy).\n",
        "\n",
        "2. The oldest Passenger was saved(80 years).\n",
        "\n",
        "3. Maximum number of deaths were in the age group of 30-40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1yZvyAqMo78"
      },
      "source": [
        "sns.factorplot('Pclass','Survived',col='Initial',data=data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVxiJxqrMvHC"
      },
      "source": [
        "The Women and Child first policy thus holds true irrespective of the class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y05I--lyMz1p"
      },
      "source": [
        "#Embarked--> Categorical Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvbOP_xUM1JT"
      },
      "source": [
        "pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpVuyTglM7AC"
      },
      "source": [
        "Chances for Survival by Port Of Embarkation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdM1oEYTM8-7"
      },
      "source": [
        "sns.factorplot('Embarked','Survived',data=data)\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(5,3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9dObW3dNAfz"
      },
      "source": [
        "The chances for survival for Port C is highest around 0.55 while it is lowest for S"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wDOAWv3NDtr"
      },
      "source": [
        "f,ax=plt.subplots(2,2,figsize=(20,15))\n",
        "sns.countplot('Embarked',data=data,ax=ax[0,0])\n",
        "ax[0,0].set_title('No. Of Passengers Boarded')\n",
        "sns.countplot('Embarked',hue='Sex',data=data,ax=ax[0,1])\n",
        "ax[0,1].set_title('Male-Female Split for Embarked')\n",
        "sns.countplot('Embarked',hue='Survived',data=data,ax=ax[1,0])\n",
        "ax[1,0].set_title('Embarked vs Survived')\n",
        "sns.countplot('Embarked',hue='Pclass',data=data,ax=ax[1,1])\n",
        "ax[1,1].set_title('Embarked vs Pclass')\n",
        "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCWuYXyENIzK"
      },
      "source": [
        "#Observations\n",
        "\n",
        "1. Maximum passenegers boarded from S. Majority of them being from Pclass3.\n",
        "\n",
        "2. The Passengers from C look to be lucky as a good proportion of them survived. The reason for this maybe the rescue of all the Pclass1 and Pclass2 Passengers.\n",
        "\n",
        "3. The Embark S looks to the port from where majority of the rich people boarded. Still the chances for survival is low here, that is because many passengers from Pclass3 around 81% didn't survive.\n",
        "\n",
        "4. Port Q had almost 95% of the passengers were from Pclass3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t2KPJkiNcvF"
      },
      "source": [
        "sns.factorplot('Pclass','Survived',hue='Sex',col='Embarked',data=data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8V9Hv-GNjjh"
      },
      "source": [
        "#Observations\n",
        "\n",
        "1. The survival chances are almost 1 for women for Pclass1 and Pclass2 irrespective of the Pclass.\n",
        "\n",
        "2. Port S looks to be very unlucky for Pclass3 Passenegers as the survival rate for both men and women is very low.(Money Matters)\n",
        "\n",
        "3. Port Q looks looks to be unlukiest for Men, as almost all were from Pclass 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeoAbLimNwo6"
      },
      "source": [
        "#Filling Embarked NaN\n",
        "\n",
        "As we saw that maximum passengers boarded from Port S, we replace NaN with S"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtvBtz_lN4d1"
      },
      "source": [
        "data['Embarked'].fillna('S',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei4FaKr5N6XL"
      },
      "source": [
        "data.Embarked.isnull().any()# Finally No NaN values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt9zEz1O196"
      },
      "source": [
        "#SibSip-->Discrete Feature\n",
        "\n",
        "This feature represents whether a person is alone or with his family members.\n",
        "\n",
        "Sibling = brother, sister, stepbrother, stepsister\n",
        "\n",
        "Spouse = husband, wife"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ2Y2hFGO-US"
      },
      "source": [
        "pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFNJGy3vXJfW"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
        "sns.barplot('SibSp','Survived',data=data,ax=ax[0])\n",
        "ax[0].set_title('SibSp vs Survived')\n",
        "sns.factorplot('SibSp','Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('SibSp vs Survived')\n",
        "plt.close(2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6MFgLfoaYV9"
      },
      "source": [
        "pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYQu4Ys0akNx"
      },
      "source": [
        "#Observations:\n",
        "The barplot and factorplot shows that if a passenger is alone onboard with no siblings, he have 34.5% survival rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38qQ-_TBapOo"
      },
      "source": [
        "Parch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzfivsPQav0g"
      },
      "source": [
        "pd.crosstab(data.Parch,data.Pclass).style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkFXVb97a2tI"
      },
      "source": [
        "The crosstab again shows that larger families were in Pclass3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_eWNNGYa7NY"
      },
      "source": [
        "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
        "sns.barplot('Parch','Survived',data=data,ax=ax[0])\n",
        "ax[0].set_title('Parch vs Survived')\n",
        "sns.factorplot('Parch','Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('Parch vs Survived')\n",
        "plt.close(2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1twfoxeIbABS"
      },
      "source": [
        "#Fare--> Continous Feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmbRpT47bItv"
      },
      "source": [
        "print('Highest Fare was:',data['Fare'].max())\n",
        "print('Lowest Fare was:',data['Fare'].min())\n",
        "print('Average Fare was:',data['Fare'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eUzg9KmbRKJ"
      },
      "source": [
        "The lowest fare is 0.0. Wow!! a free luxorious ride."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arQ5xs0NbSmY"
      },
      "source": [
        "f,ax=plt.subplots(1,3,figsize=(20,8))\n",
        "sns.distplot(data[data['Pclass']==1].Fare,ax=ax[0])\n",
        "ax[0].set_title('Fares in Pclass 1')\n",
        "sns.distplot(data[data['Pclass']==2].Fare,ax=ax[1])\n",
        "ax[1].set_title('Fares in Pclass 2')\n",
        "sns.distplot(data[data['Pclass']==3].Fare,ax=ax[2])\n",
        "ax[2].set_title('Fares in Pclass 3')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5gxotfybbIw"
      },
      "source": [
        "There looks to be a large distribution in the fares of Passengers in Pclass1 and this distribution goes on decreasing as the standards reduces. As this is also continous, we can convert into discrete values by using binning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq3JMBX5biQo"
      },
      "source": [
        "#Observations in a Nutshell for all features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ips7v3bUbpFD"
      },
      "source": [
        "Correlation Between The Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txlxjUEGbtry"
      },
      "source": [
        "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(10,8)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_pMe0-Gb6nw"
      },
      "source": [
        "#Age_band\n",
        "\n",
        "Problem With Age Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfnjQ2lRcA2s"
      },
      "source": [
        "data['Age_band']=0\n",
        "data.loc[data['Age']<=16,'Age_band']=0\n",
        "data.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\n",
        "data.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\n",
        "data.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\n",
        "data.loc[data['Age']>64,'Age_band']=4\n",
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdkDepoQcHcw"
      },
      "source": [
        "data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer')#checking the number of passenegers in each band"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY9KpL6OcLRQ"
      },
      "source": [
        "sns.factorplot('Age_band','Survived',data=data,col='Pclass')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3VNvRcPcPYH"
      },
      "source": [
        "True that..the survival rate decreases as the age increases irrespective of the Pclass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTknSSkycaxI"
      },
      "source": [
        "#Family_Size and Alone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75CR9EgScftp"
      },
      "source": [
        "data['Family_Size']=0\n",
        "data['Family_Size']=data['Parch']+data['SibSp']#family size\n",
        "data['Alone']=0\n",
        "data.loc[data.Family_Size==0,'Alone']=1#Alone\n",
        "\n",
        "f,ax=plt.subplots(1,2,figsize=(18,6))\n",
        "sns.factorplot('Family_Size','Survived',data=data,ax=ax[0])\n",
        "ax[0].set_title('Family_Size vs Survived')\n",
        "sns.factorplot('Alone','Survived',data=data,ax=ax[1])\n",
        "ax[1].set_title('Alone vs Survived')\n",
        "plt.close(2)\n",
        "plt.close(3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Uxzc7HcqhQ"
      },
      "source": [
        "**Family_Size=0 means that the passeneger is alone.** Clearly, if you are alone or family_size=0,then chances for survival is very low. For family size > 4,the chances decrease too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AiSiJVvc0IK"
      },
      "source": [
        "sns.factorplot('Alone','Survived',data=data,hue='Sex',col='Pclass')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NpTnh0Hc6FY"
      },
      "source": [
        "It is visible that being alone is harmful irrespective of Sex or Pclass except for Pclass3 where the chances of females who are alone is high than those with family."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVm_xYgVdCJr"
      },
      "source": [
        "#Fare_Range\n",
        "\n",
        "Since fare is also a continous feature, we need to convert it into ordinal value. For this we will use pandas.qcut."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a3E3NnOdLs5"
      },
      "source": [
        "data['Fare_Range']=pd.qcut(data['Fare'],4)\n",
        "data.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ssOd0YldYxv"
      },
      "source": [
        "As discussed above, we can clearly see that as the fare_range increases, the chances of survival increases.\n",
        "\n",
        "Now we cannot pass the Fare_Range values as it is. We should convert it into singleton values same as we did in Age_Band"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwYpovFUddIh"
      },
      "source": [
        "data['Fare_cat']=0\n",
        "data.loc[data['Fare']<=7.91,'Fare_cat']=0\n",
        "data.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\n",
        "data.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\n",
        "data.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VulZK4GdhkM"
      },
      "source": [
        "sns.factorplot('Fare_cat','Survived',data=data,hue='Sex')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIQzOzJCzT8J"
      },
      "source": [
        "#Converting String Values into Numeric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTOZ4kygzgw3"
      },
      "source": [
        "Since we cannot pass strings to a machine learning model, we need to convert features loke Sex, Embarked, etc into numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArOJT6hezj-Z"
      },
      "source": [
        "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
        "data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
        "data['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twlv_g7Kzs5o"
      },
      "source": [
        "#Dropping UnNeeded Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T66r078OzvZ2"
      },
      "source": [
        "data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\n",
        "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(18,15)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO7AnDSQz99m"
      },
      "source": [
        "#Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErtIDn7p0ApF"
      },
      "source": [
        "1. Logistic Regression\n",
        "\n",
        "2. Support Vector Machines(Linear and radial)\n",
        "\n",
        "3. Random Forest\n",
        "\n",
        "4. K-Nearest Neighbours\n",
        "\n",
        "5. Naive Bayes\n",
        "\n",
        "6. Decision Tree\n",
        "\n",
        "7. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuWL1O80MO3"
      },
      "source": [
        "#importing all the required ML packages\n",
        "from sklearn.linear_model import LogisticRegression #logistic regression\n",
        "from sklearn import svm #support vector Machine\n",
        "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
        "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
        "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
        "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
        "from sklearn.model_selection import train_test_split #training and testing data split\n",
        "from sklearn import metrics #accuracy measure\n",
        "from sklearn.metrics import confusion_matrix #for confusion matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYi7N7qq0Ybe"
      },
      "source": [
        "train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\n",
        "train_X=train[train.columns[1:]]\n",
        "train_Y=train[train.columns[:1]]\n",
        "test_X=test[test.columns[1:]]\n",
        "test_Y=test[test.columns[:1]]\n",
        "X=data[data.columns[1:]]\n",
        "Y=data['Survived']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jhEZAS60dNG"
      },
      "source": [
        "#Radial Support Vector Machines(rbf-SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i56-kD2h0h0E"
      },
      "source": [
        "model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
        "model.fit(train_X,train_Y)\n",
        "prediction1=model.predict(test_X)\n",
        "print('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoUOVdYj0pUb"
      },
      "source": [
        "#Linear Support Vector Machine(linear-SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsPRX9630tF5"
      },
      "source": [
        "model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\n",
        "model.fit(train_X,train_Y)\n",
        "prediction2=model.predict(test_X)\n",
        "print('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1rsejXx0w43"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giDoTOgQ0z1d"
      },
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(train_X,train_Y)\n",
        "prediction3=model.predict(test_X)\n",
        "print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction3,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2vDAE2p0567"
      },
      "source": [
        "#Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESz24iiO08yL"
      },
      "source": [
        "model=DecisionTreeClassifier()\n",
        "model.fit(train_X,train_Y)\n",
        "prediction4=model.predict(test_X)\n",
        "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32kjE-Dm1CZN"
      },
      "source": [
        "#K-Nearest Neighbours(KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOH8gc-C1GZx"
      },
      "source": [
        "model=KNeighborsClassifier() \n",
        "model.fit(train_X,train_Y)\n",
        "prediction5=model.predict(test_X)\n",
        "print('The accuracy of the KNN is',metrics.accuracy_score(prediction5,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG-3wMqMGKsd"
      },
      "source": [
        "Now the accuracy for the KNN model changes as we change the values for n_neighbours attribute. The default value is 5. Lets check the accuracies over various values of n_neighbours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEr65UNkGOxk"
      },
      "source": [
        "a_index=list(range(1,11))\n",
        "a=pd.Series()\n",
        "x=[0,1,2,3,4,5,6,7,8,9,10]\n",
        "for i in list(range(1,11)):\n",
        "    model=KNeighborsClassifier(n_neighbors=i) \n",
        "    model.fit(train_X,train_Y)\n",
        "    prediction=model.predict(test_X)\n",
        "    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))\n",
        "plt.plot(a_index, a)\n",
        "plt.xticks(x)\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(12,6)\n",
        "plt.show()\n",
        "print('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl7yOEOlGSww"
      },
      "source": [
        "#Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uWPpoVWGWgr"
      },
      "source": [
        "model=GaussianNB()\n",
        "model.fit(train_X,train_Y)\n",
        "prediction6=model.predict(test_X)\n",
        "print('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction6,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eidf1PAjGcHI"
      },
      "source": [
        "#Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkV5YJUiGgAc"
      },
      "source": [
        "model=RandomForestClassifier(n_estimators=100)\n",
        "model.fit(train_X,train_Y)\n",
        "prediction7=model.predict(test_X)\n",
        "print('The accuracy of the Random Forests is',metrics.accuracy_score(prediction7,test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F8c4FUqGjUk"
      },
      "source": [
        "#Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4v9BBZKGoFZ"
      },
      "source": [
        "from sklearn.model_selection import KFold #for K-fold cross validation\n",
        "from sklearn.model_selection import cross_val_score #score evaluation\n",
        "from sklearn.model_selection import cross_val_predict #prediction\n",
        "kfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\n",
        "xyz=[]\n",
        "accuracy=[]\n",
        "std=[]\n",
        "classifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\n",
        "models=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\n",
        "for i in models:\n",
        "    model = i\n",
        "    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n",
        "    cv_result=cv_result\n",
        "    xyz.append(cv_result.mean())\n",
        "    std.append(cv_result.std())\n",
        "    accuracy.append(cv_result)\n",
        "new_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \n",
        "new_models_dataframe2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C68BcwfGtxw"
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "box=pd.DataFrame(accuracy,index=[classifiers])\n",
        "box.T.boxplot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8SlQo8OGxum"
      },
      "source": [
        "new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\n",
        "plt.title('Average CV Mean Accuracy')\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(8,5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkt957lPG1Mv"
      },
      "source": [
        "#Confusion Matrix\n",
        "\n",
        "It gives the number of correct and incorrect classifications made by the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LagzZL-LHAQX"
      },
      "source": [
        "f,ax=plt.subplots(3,3,figsize=(12,10))\n",
        "y_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\n",
        "ax[0,0].set_title('Matrix for rbf-SVM')\n",
        "y_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\n",
        "ax[0,1].set_title('Matrix for Linear-SVM')\n",
        "y_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\n",
        "ax[0,2].set_title('Matrix for KNN')\n",
        "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\n",
        "ax[1,0].set_title('Matrix for Random-Forests')\n",
        "y_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\n",
        "ax[1,1].set_title('Matrix for Logistic Regression')\n",
        "y_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\n",
        "ax[1,2].set_title('Matrix for Decision Tree')\n",
        "y_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\n",
        "ax[2,0].set_title('Matrix for Naive Bayes')\n",
        "plt.subplots_adjust(hspace=0.2,wspace=0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbvLXq0fHKOk"
      },
      "source": [
        "#Interpreting Confusion Matrix\n",
        "\n",
        "1. The no. of correct predictions are 491(for dead) + 247(for survived) with the mean CV accuracy being (491+247)/891 = 82.8% which we did get earlier.\n",
        "\n",
        "2. Errors--> Wrongly Classified 58 dead people as survived and 95 survived as dead. Thus it has made more mistakes by predicting dead as survived."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkpWsSZcHXxP"
      },
      "source": [
        "#Hyper-Parameters Tuning\n",
        "\n",
        "The machine learning models are like a Black-Box. There are some default parameter values for this Black-Box, which we can tune or change to get a better model\n",
        "\n",
        "We will tune the hyper-parameters for the 2 best classifiers i.e the SVM and RandomForests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRhdlT-KHir7"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2nG2COdHl6i"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "C=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
        "kernel=['rbf','linear']\n",
        "hyper={'kernel':kernel,'C':C,'gamma':gamma}\n",
        "gd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\n",
        "gd.fit(X,Y)\n",
        "print(gd.best_score_)\n",
        "print(gd.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsNnFD90HtR0"
      },
      "source": [
        "#Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0UhDeDCHxTX"
      },
      "source": [
        "n_estimators=range(100,1000,100)\n",
        "hyper={'n_estimators':n_estimators}\n",
        "gd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True)\n",
        "gd.fit(X,Y)\n",
        "print(gd.best_score_)\n",
        "print(gd.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mnEdcgaH9dM"
      },
      "source": [
        "The best score for Rbf-Svm is 82.82% with C=0.05 and gamma=0.1. For RandomForest, score is abt 81.8% with n_estimators=900"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvKO8SxyICzF"
      },
      "source": [
        "#Ensembling\n",
        "\n",
        "Ensembling is a good way to increase the accuracy or performance of a model. In simple words, it is the combination of various simple models to create a single powerful mode\n",
        "\n",
        "This is Ensembling, which improves the stability of the model. Ensembling can be done in ways like:\n",
        "\n",
        "1)Voting Classifier\n",
        "\n",
        "2)Bagging\n",
        "\n",
        "3)Boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyXbM7RZINTc"
      },
      "source": [
        "#Voting Classifier\n",
        "\n",
        "It gives an average prediction result based on the prediction of all the submodels. The submodels or the basemodels are all of diiferent types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNJ8MBPQIWPG"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "ensemble_lin_rbf=VotingClassifier(estimators=[('KNN',KNeighborsClassifier(n_neighbors=10)),\n",
        "                                              ('RBF',svm.SVC(probability=True,kernel='rbf',C=0.5,gamma=0.1)),\n",
        "                                              ('RFor',RandomForestClassifier(n_estimators=500,random_state=0)),\n",
        "                                              ('LR',LogisticRegression(C=0.05)),\n",
        "                                              ('DT',DecisionTreeClassifier(random_state=0)),\n",
        "                                              ('NB',GaussianNB()),\n",
        "                                              ('svm',svm.SVC(kernel='linear',probability=True))\n",
        "                                             ], \n",
        "                       voting='soft').fit(train_X,train_Y)\n",
        "print('The accuracy for ensembled model is:',ensemble_lin_rbf.score(test_X,test_Y))\n",
        "cross=cross_val_score(ensemble_lin_rbf,X,Y, cv = 10,scoring = \"accuracy\")\n",
        "print('The cross validated score is',cross.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CadcAb2SIetM"
      },
      "source": [
        "#Bagged KNN\n",
        "\n",
        "Bagging works best with models with high variance. An example for this can be Decision Tree or Random Forests. We can use KNN with small value of n_neighbours, as small value of n_neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBsoFFXImvR"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "model=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\n",
        "model.fit(train_X,train_Y)\n",
        "prediction=model.predict(test_X)\n",
        "print('The accuracy for bagged KNN is:',metrics.accuracy_score(prediction,test_Y))\n",
        "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
        "print('The cross validated score for bagged KNN is:',result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVzQe4fJIpji"
      },
      "source": [
        "#Bagged DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJoCSr3tIuZE"
      },
      "source": [
        "model=BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,n_estimators=100)\n",
        "model.fit(train_X,train_Y)\n",
        "prediction=model.predict(test_X)\n",
        "print('The accuracy for bagged Decision Tree is:',metrics.accuracy_score(prediction,test_Y))\n",
        "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
        "print('The cross validated score for bagged Decision Tree is:',result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjPXdjgzIxSB"
      },
      "source": [
        "#Boosting\n",
        "\n",
        "Boosting is an ensembling technique which uses sequential learning of classifiers\n",
        "\n",
        "A model is first trained on the complete dataset. Now the model will get some instances right while some wrong. Now in the next iteration, the learner will focus more on the wrongly predicted instances or give more weight to it. Thus it will try to predict the wrong instance correctly. Now this iterative process continous, and new classifers are added to the model until the limit is reached on the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz5T-bQ6I6wz"
      },
      "source": [
        "#AdaBoost(Adaptive Boosting)\n",
        "\n",
        "The weak learner or estimator in this case is a Decsion Tree. But we can change the dafault base_estimator to any algorithm of our choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQmpAFyXJA0k"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\n",
        "result=cross_val_score(ada,X,Y,cv=10,scoring='accuracy')\n",
        "print('The cross validated score for AdaBoost is:',result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxuQdPnoJD6y"
      },
      "source": [
        "###Stochastic Gradient Boosting\n",
        "\n",
        "Here too the weak learner is a Decision Tree.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FRTen4RJIxO"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "grad=GradientBoostingClassifier(n_estimators=500,random_state=0,learning_rate=0.1)\n",
        "result=cross_val_score(grad,X,Y,cv=10,scoring='accuracy')\n",
        "print('The cross validated score for Gradient Boosting is:',result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVyZQEp1JLsx"
      },
      "source": [
        "###XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMRcRB8OJQIx"
      },
      "source": [
        "import xgboost as xg\n",
        "xgboost=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
        "result=cross_val_score(xgboost,X,Y,cv=10,scoring='accuracy')\n",
        "print('The cross validated score for XGBoost is:',result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n46u9BtmJS_r"
      },
      "source": [
        "We got the highest accuracy for AdaBoost. We will try to increase it with Hyper-Parameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv-ucm0JVpq"
      },
      "source": [
        "#Hyper-Parameter Tuning for AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO95PqtPJZ-D"
      },
      "source": [
        "n_estimators=list(range(100,1100,100))\n",
        "learn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
        "hyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\n",
        "gd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\n",
        "gd.fit(X,Y)\n",
        "print(gd.best_score_)\n",
        "print(gd.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN_cDdA2Jefy"
      },
      "source": [
        "The maximum accuracy we can get with AdaBoost is 83.16% with n_estimators=200 and learning_rate=0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWMEQmd1JiUA"
      },
      "source": [
        "###Confusion Matrix for the Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atVlaiYRJmWt"
      },
      "source": [
        "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.05)\n",
        "result=cross_val_predict(ada,X,Y,cv=10)\n",
        "sns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True,fmt='2.0f')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRqBvQX8J1kG"
      },
      "source": [
        "###Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCdNQRYZK6W3"
      },
      "source": [
        "f,ax=plt.subplots(2,2,figsize=(15,12))\n",
        "model=RandomForestClassifier(n_estimators=500,random_state=0)\n",
        "model.fit(X,Y)\n",
        "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\n",
        "ax[0,0].set_title('Feature Importance in Random Forests')\n",
        "model=AdaBoostClassifier(n_estimators=200,learning_rate=0.05,random_state=0)\n",
        "model.fit(X,Y)\n",
        "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\n",
        "ax[0,1].set_title('Feature Importance in AdaBoost')\n",
        "model=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=0)\n",
        "model.fit(X,Y)\n",
        "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\n",
        "ax[1,0].set_title('Feature Importance in Gradient Boosting')\n",
        "model=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
        "model.fit(X,Y)\n",
        "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\n",
        "ax[1,1].set_title('Feature Importance in XgBoost')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}